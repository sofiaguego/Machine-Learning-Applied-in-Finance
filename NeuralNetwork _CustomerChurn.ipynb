{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109ed804",
   "metadata": {},
   "source": [
    "Author: Sofia Guerrero\n",
    "\n",
    "\n",
    "The purpose of this Jupyter Notebook is to create a Neural Network Model to classify if a new customer is most likely to stay at the bank or not given its information.\n",
    "\n",
    "Let's find out! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c40211ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792306c9",
   "metadata": {},
   "source": [
    "# Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16392f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>645</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>822</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>501</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>684</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>528</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>102016.72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80181.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "5          645   44       8  113755.78              2          1   \n",
       "6          822   50       7       0.00              2          1   \n",
       "7          501   44       4  142051.07              2          0   \n",
       "8          684   27       2  134603.88              1          1   \n",
       "9          528   31       6  102016.72              2          0   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Gender_Female  Gender_Male  \n",
       "0               1        101348.88       1            1.0          0.0  \n",
       "1               1        112542.58       0            1.0          0.0  \n",
       "2               0        113931.57       1            1.0          0.0  \n",
       "3               0         93826.63       0            1.0          0.0  \n",
       "4               1         79084.10       0            1.0          0.0  \n",
       "5               0        149756.71       1            0.0          1.0  \n",
       "6               1         10062.80       0            0.0          1.0  \n",
       "7               1         74940.50       0            0.0          1.0  \n",
       "8               1         71725.73       0            0.0          1.0  \n",
       "9               0         80181.12       0            0.0          1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('FINAL-churn-model-cleaned.csv')\n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebc64c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "Gender_Female      0\n",
       "Gender_Male        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb235a5",
   "metadata": {},
   "source": [
    "# Scaling the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3709143",
   "metadata": {},
   "source": [
    "Here, I will drop Exited since it is the predicted label.\n",
    "\n",
    "- Also, for the columns: HasCrCard, IsActiveMember, Gender_Female, Gender_Male, they are binary colums so it's not necessary to scale.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aaf1fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Gender_Female', 'Gender_Male'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_scale = df.drop(columns=[\"Exited\"]).columns\n",
    "columns_to_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1208748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_scale = [\"CreditScore\", \"Age\", \"Tenure\", 'Balance', 'NumOfProducts',\n",
    "        'EstimatedSalary']\n",
    "columns_to_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57232dc8",
   "metadata": {},
   "source": [
    "__Standard Scaler__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc9c2e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "scaler = StandardScaler()\n",
    "df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87946486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.329808</td>\n",
       "      <td>0.485534</td>\n",
       "      <td>-1.044203</td>\n",
       "      <td>-1.224651</td>\n",
       "      <td>-0.938614</td>\n",
       "      <td>0.021813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.444286</td>\n",
       "      <td>0.371671</td>\n",
       "      <td>-1.390497</td>\n",
       "      <td>0.118145</td>\n",
       "      <td>-0.938614</td>\n",
       "      <td>0.216419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.547436</td>\n",
       "      <td>0.485534</td>\n",
       "      <td>1.033562</td>\n",
       "      <td>1.333486</td>\n",
       "      <td>2.699489</td>\n",
       "      <td>0.240567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.502758</td>\n",
       "      <td>0.143947</td>\n",
       "      <td>-1.390497</td>\n",
       "      <td>-1.224651</td>\n",
       "      <td>0.880438</td>\n",
       "      <td>-0.108963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.074226</td>\n",
       "      <td>0.599396</td>\n",
       "      <td>-1.044203</td>\n",
       "      <td>0.786324</td>\n",
       "      <td>-0.938614</td>\n",
       "      <td>-0.365266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>1.252067</td>\n",
       "      <td>0.143947</td>\n",
       "      <td>-0.005320</td>\n",
       "      <td>-1.224651</td>\n",
       "      <td>0.880438</td>\n",
       "      <td>-0.066473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>-1.401737</td>\n",
       "      <td>-0.311503</td>\n",
       "      <td>1.726151</td>\n",
       "      <td>-0.305457</td>\n",
       "      <td>-0.938614</td>\n",
       "      <td>0.027914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>0.606829</td>\n",
       "      <td>-0.197641</td>\n",
       "      <td>0.687268</td>\n",
       "      <td>-1.224651</td>\n",
       "      <td>-0.938614</td>\n",
       "      <td>-1.008495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9566</th>\n",
       "      <td>1.262474</td>\n",
       "      <td>0.485534</td>\n",
       "      <td>-0.697909</td>\n",
       "      <td>-0.021770</td>\n",
       "      <td>0.880438</td>\n",
       "      <td>-0.125272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9567</th>\n",
       "      <td>1.470616</td>\n",
       "      <td>-1.108541</td>\n",
       "      <td>-0.351615</td>\n",
       "      <td>0.860539</td>\n",
       "      <td>-0.938614</td>\n",
       "      <td>-1.076207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9568 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age    Tenure   Balance  NumOfProducts  \\\n",
       "0       -0.329808  0.485534 -1.044203 -1.224651      -0.938614   \n",
       "1       -0.444286  0.371671 -1.390497  0.118145      -0.938614   \n",
       "2       -1.547436  0.485534  1.033562  1.333486       2.699489   \n",
       "3        0.502758  0.143947 -1.390497 -1.224651       0.880438   \n",
       "4        2.074226  0.599396 -1.044203  0.786324      -0.938614   \n",
       "...           ...       ...       ...       ...            ...   \n",
       "9563     1.252067  0.143947 -0.005320 -1.224651       0.880438   \n",
       "9564    -1.401737 -0.311503  1.726151 -0.305457      -0.938614   \n",
       "9565     0.606829 -0.197641  0.687268 -1.224651      -0.938614   \n",
       "9566     1.262474  0.485534 -0.697909 -0.021770       0.880438   \n",
       "9567     1.470616 -1.108541 -0.351615  0.860539      -0.938614   \n",
       "\n",
       "      EstimatedSalary  \n",
       "0            0.021813  \n",
       "1            0.216419  \n",
       "2            0.240567  \n",
       "3           -0.108963  \n",
       "4           -0.365266  \n",
       "...               ...  \n",
       "9563        -0.066473  \n",
       "9564         0.027914  \n",
       "9565        -1.008495  \n",
       "9566        -0.125272  \n",
       "9567        -1.076207  \n",
       "\n",
       "[9568 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[columns_to_scale]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db9316e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.329808</td>\n",
       "      <td>0.485534</td>\n",
       "      <td>-1.044203</td>\n",
       "      <td>-1.224651</td>\n",
       "      <td>-0.938614</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021813</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.444286</td>\n",
       "      <td>0.371671</td>\n",
       "      <td>-1.390497</td>\n",
       "      <td>0.118145</td>\n",
       "      <td>-0.938614</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216419</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.547436</td>\n",
       "      <td>0.485534</td>\n",
       "      <td>1.033562</td>\n",
       "      <td>1.333486</td>\n",
       "      <td>2.699489</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240567</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.502758</td>\n",
       "      <td>0.143947</td>\n",
       "      <td>-1.390497</td>\n",
       "      <td>-1.224651</td>\n",
       "      <td>0.880438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.108963</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.074226</td>\n",
       "      <td>0.599396</td>\n",
       "      <td>-1.044203</td>\n",
       "      <td>0.786324</td>\n",
       "      <td>-0.938614</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.365266</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.152888</td>\n",
       "      <td>-0.653091</td>\n",
       "      <td>1.033562</td>\n",
       "      <td>-1.224651</td>\n",
       "      <td>0.880438</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.668660</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.464179</td>\n",
       "      <td>0.030084</td>\n",
       "      <td>-0.351615</td>\n",
       "      <td>-1.224651</td>\n",
       "      <td>-0.938614</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.327179</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.190546</td>\n",
       "      <td>0.940984</td>\n",
       "      <td>-0.697909</td>\n",
       "      <td>-1.224651</td>\n",
       "      <td>0.880438</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.592602</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.032598</td>\n",
       "      <td>0.030084</td>\n",
       "      <td>-0.005320</td>\n",
       "      <td>-1.224651</td>\n",
       "      <td>-0.938614</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.521593</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.766905</td>\n",
       "      <td>-1.450128</td>\n",
       "      <td>-0.697909</td>\n",
       "      <td>-1.224651</td>\n",
       "      <td>0.880438</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.424446</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0     -0.329808  0.485534 -1.044203 -1.224651      -0.938614          1   \n",
       "1     -0.444286  0.371671 -1.390497  0.118145      -0.938614          0   \n",
       "2     -1.547436  0.485534  1.033562  1.333486       2.699489          1   \n",
       "3      0.502758  0.143947 -1.390497 -1.224651       0.880438          0   \n",
       "4      2.074226  0.599396 -1.044203  0.786324      -0.938614          1   \n",
       "..          ...       ...       ...       ...            ...        ...   \n",
       "20    -0.152888 -0.653091  1.033562 -1.224651       0.880438          1   \n",
       "21    -1.464179  0.030084 -0.351615 -1.224651      -0.938614          1   \n",
       "22     0.190546  0.940984 -0.697909 -1.224651       0.880438          0   \n",
       "23     2.032598  0.030084 -0.005320 -1.224651      -0.938614          1   \n",
       "24    -0.766905 -1.450128 -0.697909 -1.224651       0.880438          0   \n",
       "\n",
       "    IsActiveMember  EstimatedSalary  Exited  Gender_Female  Gender_Male  \n",
       "0                1         0.021813       1            1.0          0.0  \n",
       "1                1         0.216419       0            1.0          0.0  \n",
       "2                0         0.240567       1            1.0          0.0  \n",
       "3                0        -0.108963       0            1.0          0.0  \n",
       "4                1        -0.365266       0            1.0          0.0  \n",
       "..             ...              ...     ...            ...          ...  \n",
       "20               0         0.668660       0            1.0          0.0  \n",
       "21               0         0.327179       1            1.0          0.0  \n",
       "22               1        -1.592602       0            0.0          1.0  \n",
       "23               1         1.521593       0            1.0          0.0  \n",
       "24               1         0.424446       0            0.0          1.0  \n",
       "\n",
       "[25 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "961d2fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        float64\n",
       "Age                float64\n",
       "Tenure             float64\n",
       "Balance            float64\n",
       "NumOfProducts      float64\n",
       "                    ...   \n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "Gender_Female      float64\n",
       "Gender_Male        float64\n",
       "Length: 11, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be81afc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "                  ..\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "Gender_Female      0\n",
       "Gender_Male        0\n",
       "Length: 11, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "283b1d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.329808</td>\n",
       "      <td>0.485534</td>\n",
       "      <td>-1.044203</td>\n",
       "      <td>-1.224651</td>\n",
       "      <td>-0.938614</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021813</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.444286</td>\n",
       "      <td>0.371671</td>\n",
       "      <td>-1.390497</td>\n",
       "      <td>0.118145</td>\n",
       "      <td>-0.938614</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216419</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.547436</td>\n",
       "      <td>0.485534</td>\n",
       "      <td>1.033562</td>\n",
       "      <td>1.333486</td>\n",
       "      <td>2.699489</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240567</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.502758</td>\n",
       "      <td>0.143947</td>\n",
       "      <td>-1.390497</td>\n",
       "      <td>-1.224651</td>\n",
       "      <td>0.880438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.108963</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.074226</td>\n",
       "      <td>0.599396</td>\n",
       "      <td>-1.044203</td>\n",
       "      <td>0.786324</td>\n",
       "      <td>-0.938614</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.365266</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.059224</td>\n",
       "      <td>0.713259</td>\n",
       "      <td>1.033562</td>\n",
       "      <td>0.597981</td>\n",
       "      <td>0.880438</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.863396</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.782828</td>\n",
       "      <td>1.396434</td>\n",
       "      <td>0.687268</td>\n",
       "      <td>-1.224651</td>\n",
       "      <td>0.880438</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.565220</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.557843</td>\n",
       "      <td>0.713259</td>\n",
       "      <td>-0.351615</td>\n",
       "      <td>1.051337</td>\n",
       "      <td>0.880438</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.437304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.346652</td>\n",
       "      <td>-1.222403</td>\n",
       "      <td>-1.044203</td>\n",
       "      <td>0.932016</td>\n",
       "      <td>-0.938614</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.493193</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.276852</td>\n",
       "      <td>-0.766953</td>\n",
       "      <td>0.340974</td>\n",
       "      <td>0.409894</td>\n",
       "      <td>0.880438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.346194</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0    -0.329808  0.485534 -1.044203 -1.224651      -0.938614          1   \n",
       "1    -0.444286  0.371671 -1.390497  0.118145      -0.938614          0   \n",
       "2    -1.547436  0.485534  1.033562  1.333486       2.699489          1   \n",
       "3     0.502758  0.143947 -1.390497 -1.224651       0.880438          0   \n",
       "4     2.074226  0.599396 -1.044203  0.786324      -0.938614          1   \n",
       "5    -0.059224  0.713259  1.033562  0.597981       0.880438          1   \n",
       "6     1.782828  1.396434  0.687268 -1.224651       0.880438          1   \n",
       "7    -1.557843  0.713259 -0.351615  1.051337       0.880438          0   \n",
       "8     0.346652 -1.222403 -1.044203  0.932016      -0.938614          1   \n",
       "9    -1.276852 -0.766953  0.340974  0.409894       0.880438          0   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Gender_Female  Gender_Male  \n",
       "0               1         0.021813       1            1.0          0.0  \n",
       "1               1         0.216419       0            1.0          0.0  \n",
       "2               0         0.240567       1            1.0          0.0  \n",
       "3               0        -0.108963       0            1.0          0.0  \n",
       "4               1        -0.365266       0            1.0          0.0  \n",
       "5               0         0.863396       1            0.0          1.0  \n",
       "6               1        -1.565220       0            0.0          1.0  \n",
       "7               1        -0.437304       0            0.0          1.0  \n",
       "8               1        -0.493193       0            0.0          1.0  \n",
       "9               0        -0.346194       0            0.0          1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db329314",
   "metadata": {},
   "source": [
    "__Saving Scaler:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd6e38f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'scaler_model.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9240c4",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba9a5be",
   "metadata": {},
   "source": [
    "Split the dataset into Train and Test dataframe with the ratio of 75% for Train and 25% for Test. Also report how many records exist in both train and test dataframes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a447c868",
   "metadata": {},
   "source": [
    "__Splitting Train and Test Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68e84a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in train DataFrame: 7176\n",
      "Number of records in test DataFrame: 2392\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['Exited'])\n",
    "y = df['Exited']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "print(\"Number of records in train DataFrame:\", len(X_train))\n",
    "print(\"Number of records in test DataFrame:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fed17e",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076d0a57",
   "metadata": {},
   "source": [
    "Designing a Neural Network Classifier to identify if a customer leave (exit) the bank with the following parameters:\n",
    "\n",
    "-\tSet 15% of training as Validation dataset\n",
    "-\tSet a minimum of 2 hidden layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca6c6f3",
   "metadata": {},
   "source": [
    "__Neural Network Classifier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "786d5ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.55694516\n",
      "Validation score: 0.803980\n",
      "Iteration 2, loss = 0.49366597\n",
      "Validation score: 0.803980\n",
      "Iteration 3, loss = 0.49021410\n",
      "Validation score: 0.803980\n",
      "Iteration 4, loss = 0.48704511\n",
      "Validation score: 0.803980\n",
      "Iteration 5, loss = 0.48344497\n",
      "Validation score: 0.803980\n",
      "Iteration 6, loss = 0.47918173\n",
      "Validation score: 0.803980\n",
      "Iteration 7, loss = 0.47400055\n",
      "Validation score: 0.803980\n",
      "Iteration 8, loss = 0.46782305\n",
      "Validation score: 0.803980\n",
      "Iteration 9, loss = 0.46046010\n",
      "Validation score: 0.803980\n",
      "Iteration 10, loss = 0.45240676\n",
      "Validation score: 0.803980\n",
      "Iteration 11, loss = 0.44306622\n",
      "Validation score: 0.803980\n",
      "Iteration 12, loss = 0.43538321\n",
      "Validation score: 0.803980\n",
      "Iteration 13, loss = 0.42686988\n",
      "Validation score: 0.808955\n",
      "Iteration 14, loss = 0.42060384\n",
      "Validation score: 0.813930\n",
      "Iteration 15, loss = 0.41569184\n",
      "Validation score: 0.816915\n",
      "Iteration 16, loss = 0.41264815\n",
      "Validation score: 0.818905\n",
      "Iteration 17, loss = 0.41024225\n",
      "Validation score: 0.821891\n",
      "Iteration 18, loss = 0.40891418\n",
      "Validation score: 0.818905\n",
      "Iteration 19, loss = 0.40795737\n",
      "Validation score: 0.817910\n",
      "Iteration 20, loss = 0.40742135\n",
      "Validation score: 0.820896\n",
      "Iteration 21, loss = 0.40738176\n",
      "Validation score: 0.821891\n",
      "Iteration 22, loss = 0.40688983\n",
      "Validation score: 0.818905\n",
      "Iteration 23, loss = 0.40702074\n",
      "Validation score: 0.822886\n",
      "Iteration 24, loss = 0.40659741\n",
      "Validation score: 0.817910\n",
      "Iteration 25, loss = 0.40650015\n",
      "Validation score: 0.817910\n",
      "Iteration 26, loss = 0.40622552\n",
      "Validation score: 0.816915\n",
      "Iteration 27, loss = 0.40637953\n",
      "Validation score: 0.818905\n",
      "Iteration 28, loss = 0.40626662\n",
      "Validation score: 0.818905\n",
      "Iteration 29, loss = 0.40587463\n",
      "Validation score: 0.818905\n",
      "Iteration 30, loss = 0.40586086\n",
      "Validation score: 0.819900\n",
      "Iteration 31, loss = 0.40588048\n",
      "Validation score: 0.817910\n",
      "Iteration 32, loss = 0.40632221\n",
      "Validation score: 0.819900\n",
      "Iteration 33, loss = 0.40591793\n",
      "Validation score: 0.820896\n",
      "Iteration 34, loss = 0.40567362\n",
      "Validation score: 0.817910\n",
      "Iteration 35, loss = 0.40561907\n",
      "Validation score: 0.820896\n",
      "Iteration 36, loss = 0.40547037\n",
      "Validation score: 0.820896\n",
      "Iteration 37, loss = 0.40557329\n",
      "Validation score: 0.822886\n",
      "Iteration 38, loss = 0.40524517\n",
      "Validation score: 0.816915\n",
      "Iteration 39, loss = 0.40524143\n",
      "Validation score: 0.819900\n",
      "Iteration 40, loss = 0.40526056\n",
      "Validation score: 0.817910\n",
      "Iteration 41, loss = 0.40519658\n",
      "Validation score: 0.817910\n",
      "Iteration 42, loss = 0.40561715\n",
      "Validation score: 0.819900\n",
      "Iteration 43, loss = 0.40462717\n",
      "Validation score: 0.816915\n",
      "Iteration 44, loss = 0.40503460\n",
      "Validation score: 0.815920\n",
      "Iteration 45, loss = 0.40494821\n",
      "Validation score: 0.818905\n",
      "Iteration 46, loss = 0.40538665\n",
      "Validation score: 0.819900\n",
      "Iteration 47, loss = 0.40452794\n",
      "Validation score: 0.819900\n",
      "Iteration 48, loss = 0.40439946\n",
      "Validation score: 0.819900\n",
      "Iteration 49, loss = 0.40404903\n",
      "Validation score: 0.819900\n",
      "Iteration 50, loss = 0.40386242\n",
      "Validation score: 0.820896\n",
      "Iteration 51, loss = 0.40379952\n",
      "Validation score: 0.819900\n",
      "Iteration 52, loss = 0.40346073\n",
      "Validation score: 0.816915\n",
      "Iteration 53, loss = 0.40337153\n",
      "Validation score: 0.819900\n",
      "Iteration 54, loss = 0.40321440\n",
      "Validation score: 0.819900\n",
      "Iteration 55, loss = 0.40299119\n",
      "Validation score: 0.818905\n",
      "Iteration 56, loss = 0.40268180\n",
      "Validation score: 0.817910\n",
      "Iteration 57, loss = 0.40260443\n",
      "Validation score: 0.817910\n",
      "Iteration 58, loss = 0.40193339\n",
      "Validation score: 0.818905\n",
      "Iteration 59, loss = 0.40225606\n",
      "Validation score: 0.819900\n",
      "Iteration 60, loss = 0.40210526\n",
      "Validation score: 0.820896\n",
      "Iteration 61, loss = 0.40116942\n",
      "Validation score: 0.818905\n",
      "Iteration 62, loss = 0.40104715\n",
      "Validation score: 0.816915\n",
      "Iteration 63, loss = 0.40066903\n",
      "Validation score: 0.819900\n",
      "Iteration 64, loss = 0.40094003\n",
      "Validation score: 0.821891\n",
      "Iteration 65, loss = 0.40089228\n",
      "Validation score: 0.819900\n",
      "Iteration 66, loss = 0.39989480\n",
      "Validation score: 0.819900\n",
      "Iteration 67, loss = 0.39966143\n",
      "Validation score: 0.814925\n",
      "Iteration 68, loss = 0.39883821\n",
      "Validation score: 0.815920\n",
      "Iteration 69, loss = 0.39839189\n",
      "Validation score: 0.819900\n",
      "Iteration 70, loss = 0.39776773\n",
      "Validation score: 0.819900\n",
      "Iteration 71, loss = 0.39868367\n",
      "Validation score: 0.816915\n",
      "Iteration 72, loss = 0.39779512\n",
      "Validation score: 0.816915\n",
      "Iteration 73, loss = 0.39620324\n",
      "Validation score: 0.822886\n",
      "Iteration 74, loss = 0.39722882\n",
      "Validation score: 0.817910\n",
      "Iteration 75, loss = 0.39567195\n",
      "Validation score: 0.817910\n",
      "Iteration 76, loss = 0.39493236\n",
      "Validation score: 0.818905\n",
      "Iteration 77, loss = 0.39446301\n",
      "Validation score: 0.818905\n",
      "Iteration 78, loss = 0.39393896\n",
      "Validation score: 0.818905\n",
      "Iteration 79, loss = 0.39325636\n",
      "Validation score: 0.819900\n",
      "Iteration 80, loss = 0.39276598\n",
      "Validation score: 0.822886\n",
      "Iteration 81, loss = 0.39258923\n",
      "Validation score: 0.819900\n",
      "Iteration 82, loss = 0.39162697\n",
      "Validation score: 0.818905\n",
      "Iteration 83, loss = 0.39057084\n",
      "Validation score: 0.818905\n",
      "Iteration 84, loss = 0.38973807\n",
      "Validation score: 0.821891\n",
      "Iteration 85, loss = 0.38899750\n",
      "Validation score: 0.818905\n",
      "Iteration 86, loss = 0.38911336\n",
      "Validation score: 0.822886\n",
      "Iteration 87, loss = 0.38729038\n",
      "Validation score: 0.820896\n",
      "Iteration 88, loss = 0.38688463\n",
      "Validation score: 0.821891\n",
      "Iteration 89, loss = 0.38541286\n",
      "Validation score: 0.824876\n",
      "Iteration 90, loss = 0.38455016\n",
      "Validation score: 0.823881\n",
      "Iteration 91, loss = 0.38437126\n",
      "Validation score: 0.826866\n",
      "Iteration 92, loss = 0.38294348\n",
      "Validation score: 0.833831\n",
      "Iteration 93, loss = 0.38194349\n",
      "Validation score: 0.831841\n",
      "Iteration 94, loss = 0.38123948\n",
      "Validation score: 0.830846\n",
      "Iteration 95, loss = 0.37915159\n",
      "Validation score: 0.829851\n",
      "Iteration 96, loss = 0.37827921\n",
      "Validation score: 0.832836\n",
      "Iteration 97, loss = 0.37691245\n",
      "Validation score: 0.835821\n",
      "Iteration 98, loss = 0.37594136\n",
      "Validation score: 0.831841\n",
      "Iteration 99, loss = 0.37498878\n",
      "Validation score: 0.836816\n",
      "Iteration 100, loss = 0.37386287\n",
      "Validation score: 0.837811\n",
      "Iteration 101, loss = 0.37310784\n",
      "Validation score: 0.839801\n",
      "Iteration 102, loss = 0.37128094\n",
      "Validation score: 0.836816\n",
      "Iteration 103, loss = 0.37007994\n",
      "Validation score: 0.834826\n",
      "Iteration 104, loss = 0.36919522\n",
      "Validation score: 0.836816\n",
      "Iteration 105, loss = 0.36743701\n",
      "Validation score: 0.837811\n",
      "Iteration 106, loss = 0.36662968\n",
      "Validation score: 0.839801\n",
      "Iteration 107, loss = 0.36560796\n",
      "Validation score: 0.842786\n",
      "Iteration 108, loss = 0.36599427\n",
      "Validation score: 0.840796\n",
      "Iteration 109, loss = 0.36439398\n",
      "Validation score: 0.844776\n",
      "Iteration 110, loss = 0.36279835\n",
      "Validation score: 0.848756\n",
      "Iteration 111, loss = 0.36164107\n",
      "Validation score: 0.847761\n",
      "Iteration 112, loss = 0.36109826\n",
      "Validation score: 0.847761\n",
      "Iteration 113, loss = 0.36026625\n",
      "Validation score: 0.846766\n",
      "Iteration 114, loss = 0.35982849\n",
      "Validation score: 0.849751\n",
      "Iteration 115, loss = 0.35878633\n",
      "Validation score: 0.849751\n",
      "Iteration 116, loss = 0.35820276\n",
      "Validation score: 0.847761\n",
      "Iteration 117, loss = 0.35796378\n",
      "Validation score: 0.848756\n",
      "Iteration 118, loss = 0.35802553\n",
      "Validation score: 0.851741\n",
      "Iteration 119, loss = 0.35806675\n",
      "Validation score: 0.851741\n",
      "Iteration 120, loss = 0.35700060\n",
      "Validation score: 0.849751\n",
      "Iteration 121, loss = 0.35545302\n",
      "Validation score: 0.849751\n",
      "Iteration 122, loss = 0.35576645\n",
      "Validation score: 0.850746\n",
      "Iteration 123, loss = 0.35499579\n",
      "Validation score: 0.853731\n",
      "Iteration 124, loss = 0.35488830\n",
      "Validation score: 0.849751\n",
      "Iteration 125, loss = 0.35578854\n",
      "Validation score: 0.852736\n",
      "Iteration 126, loss = 0.35445907\n",
      "Validation score: 0.852736\n",
      "Iteration 127, loss = 0.35382659\n",
      "Validation score: 0.850746\n",
      "Iteration 128, loss = 0.35443818\n",
      "Validation score: 0.854726\n",
      "Iteration 129, loss = 0.35339450\n",
      "Validation score: 0.852736\n",
      "Iteration 130, loss = 0.35318999\n",
      "Validation score: 0.852736\n",
      "Iteration 131, loss = 0.35291272\n",
      "Validation score: 0.852736\n",
      "Iteration 132, loss = 0.35258263\n",
      "Validation score: 0.853731\n",
      "Iteration 133, loss = 0.35332518\n",
      "Validation score: 0.851741\n",
      "Iteration 134, loss = 0.35257345\n",
      "Validation score: 0.854726\n",
      "Iteration 135, loss = 0.35230640\n",
      "Validation score: 0.853731\n",
      "Iteration 136, loss = 0.35206493\n",
      "Validation score: 0.852736\n",
      "Iteration 137, loss = 0.35238075\n",
      "Validation score: 0.853731\n",
      "Iteration 138, loss = 0.35158688\n",
      "Validation score: 0.853731\n",
      "Iteration 139, loss = 0.35138407\n",
      "Validation score: 0.851741\n",
      "Iteration 140, loss = 0.35183876\n",
      "Validation score: 0.850746\n",
      "Iteration 141, loss = 0.35165017\n",
      "Validation score: 0.854726\n",
      "Iteration 142, loss = 0.35160750\n",
      "Validation score: 0.851741\n",
      "Iteration 143, loss = 0.35125379\n",
      "Validation score: 0.853731\n",
      "Iteration 144, loss = 0.35176460\n",
      "Validation score: 0.853731\n",
      "Iteration 145, loss = 0.35136480\n",
      "Validation score: 0.853731\n",
      "Iteration 146, loss = 0.35173162\n",
      "Validation score: 0.852736\n",
      "Iteration 147, loss = 0.35156836\n",
      "Validation score: 0.854726\n",
      "Iteration 148, loss = 0.35080035\n",
      "Validation score: 0.852736\n",
      "Iteration 149, loss = 0.35105504\n",
      "Validation score: 0.853731\n",
      "Iteration 150, loss = 0.35067482\n",
      "Validation score: 0.854726\n",
      "Iteration 151, loss = 0.35045842\n",
      "Validation score: 0.854726\n",
      "Iteration 152, loss = 0.35061348\n",
      "Validation score: 0.851741\n",
      "Iteration 153, loss = 0.35078257\n",
      "Validation score: 0.852736\n",
      "Iteration 154, loss = 0.35012304\n",
      "Validation score: 0.853731\n",
      "Iteration 155, loss = 0.35004458\n",
      "Validation score: 0.853731\n",
      "Iteration 156, loss = 0.35092684\n",
      "Validation score: 0.853731\n",
      "Iteration 157, loss = 0.35023958\n",
      "Validation score: 0.852736\n",
      "Iteration 158, loss = 0.35018277\n",
      "Validation score: 0.852736\n",
      "Iteration 159, loss = 0.35025836\n",
      "Validation score: 0.854726\n",
      "Iteration 160, loss = 0.34991808\n",
      "Validation score: 0.854726\n",
      "Iteration 161, loss = 0.34970012\n",
      "Validation score: 0.855721\n",
      "Iteration 162, loss = 0.35007480\n",
      "Validation score: 0.853731\n",
      "Iteration 163, loss = 0.34968257\n",
      "Validation score: 0.854726\n",
      "Iteration 164, loss = 0.34936597\n",
      "Validation score: 0.852736\n",
      "Iteration 165, loss = 0.35003556\n",
      "Validation score: 0.854726\n",
      "Iteration 166, loss = 0.35019514\n",
      "Validation score: 0.853731\n",
      "Iteration 167, loss = 0.35051941\n",
      "Validation score: 0.854726\n",
      "Iteration 168, loss = 0.34939808\n",
      "Validation score: 0.855721\n",
      "Iteration 169, loss = 0.34927359\n",
      "Validation score: 0.855721\n",
      "Iteration 170, loss = 0.34949053\n",
      "Validation score: 0.854726\n",
      "Iteration 171, loss = 0.34950568\n",
      "Validation score: 0.853731\n",
      "Iteration 172, loss = 0.34913831\n",
      "Validation score: 0.853731\n",
      "Iteration 173, loss = 0.34951653\n",
      "Validation score: 0.855721\n",
      "Iteration 174, loss = 0.34859830\n",
      "Validation score: 0.853731\n",
      "Iteration 175, loss = 0.34918322\n",
      "Validation score: 0.855721\n",
      "Iteration 176, loss = 0.35021590\n",
      "Validation score: 0.855721\n",
      "Iteration 177, loss = 0.34915121\n",
      "Validation score: 0.856716\n",
      "Iteration 178, loss = 0.34908132\n",
      "Validation score: 0.855721\n",
      "Iteration 179, loss = 0.34859793\n",
      "Validation score: 0.853731\n",
      "Iteration 180, loss = 0.34961932\n",
      "Validation score: 0.855721\n",
      "Iteration 181, loss = 0.34915249\n",
      "Validation score: 0.853731\n",
      "Iteration 182, loss = 0.34825933\n",
      "Validation score: 0.853731\n",
      "Iteration 183, loss = 0.34867106\n",
      "Validation score: 0.856716\n",
      "Iteration 184, loss = 0.34874904\n",
      "Validation score: 0.857711\n",
      "Iteration 185, loss = 0.34830540\n",
      "Validation score: 0.856716\n",
      "Iteration 186, loss = 0.34874206\n",
      "Validation score: 0.856716\n",
      "Iteration 187, loss = 0.34851785\n",
      "Validation score: 0.854726\n",
      "Iteration 188, loss = 0.34823809\n",
      "Validation score: 0.854726\n",
      "Iteration 189, loss = 0.34832637\n",
      "Validation score: 0.854726\n",
      "Iteration 190, loss = 0.34774992\n",
      "Validation score: 0.854726\n",
      "Iteration 191, loss = 0.34826287\n",
      "Validation score: 0.855721\n",
      "Iteration 192, loss = 0.34817714\n",
      "Validation score: 0.855721\n",
      "Iteration 193, loss = 0.34810495\n",
      "Validation score: 0.853731\n",
      "Iteration 194, loss = 0.34990126\n",
      "Validation score: 0.852736\n",
      "Iteration 195, loss = 0.34817628\n",
      "Validation score: 0.855721\n",
      "Iteration 196, loss = 0.34815990\n",
      "Validation score: 0.854726\n",
      "Iteration 197, loss = 0.34804977\n",
      "Validation score: 0.856716\n",
      "Iteration 198, loss = 0.34767651\n",
      "Validation score: 0.855721\n",
      "Iteration 199, loss = 0.34767928\n",
      "Validation score: 0.853731\n",
      "Iteration 200, loss = 0.34741717\n",
      "Validation score: 0.857711\n",
      "Iteration 201, loss = 0.34739482\n",
      "Validation score: 0.855721\n",
      "Iteration 202, loss = 0.34772780\n",
      "Validation score: 0.856716\n",
      "Iteration 203, loss = 0.34727222\n",
      "Validation score: 0.853731\n",
      "Iteration 204, loss = 0.34745577\n",
      "Validation score: 0.854726\n",
      "Iteration 205, loss = 0.34733548\n",
      "Validation score: 0.855721\n",
      "Iteration 206, loss = 0.34711663\n",
      "Validation score: 0.856716\n",
      "Iteration 207, loss = 0.34731378\n",
      "Validation score: 0.854726\n",
      "Iteration 208, loss = 0.34742085\n",
      "Validation score: 0.855721\n",
      "Iteration 209, loss = 0.34710953\n",
      "Validation score: 0.851741\n",
      "Iteration 210, loss = 0.34743077\n",
      "Validation score: 0.854726\n",
      "Iteration 211, loss = 0.34729664\n",
      "Validation score: 0.856716\n",
      "Iteration 212, loss = 0.34742890\n",
      "Validation score: 0.856716\n",
      "Iteration 213, loss = 0.34692433\n",
      "Validation score: 0.857711\n",
      "Iteration 214, loss = 0.34700274\n",
      "Validation score: 0.853731\n",
      "Iteration 215, loss = 0.34717753\n",
      "Validation score: 0.853731\n",
      "Iteration 216, loss = 0.34715499\n",
      "Validation score: 0.852736\n",
      "Iteration 217, loss = 0.34677693\n",
      "Validation score: 0.852736\n",
      "Iteration 218, loss = 0.34708912\n",
      "Validation score: 0.852736\n",
      "Iteration 219, loss = 0.34705145\n",
      "Validation score: 0.856716\n",
      "Iteration 220, loss = 0.34681661\n",
      "Validation score: 0.857711\n",
      "Iteration 221, loss = 0.34658225\n",
      "Validation score: 0.857711\n",
      "Iteration 222, loss = 0.34636639\n",
      "Validation score: 0.854726\n",
      "Iteration 223, loss = 0.34658887\n",
      "Validation score: 0.854726\n",
      "Iteration 224, loss = 0.34712050\n",
      "Validation score: 0.855721\n",
      "Iteration 225, loss = 0.34654657\n",
      "Validation score: 0.856716\n",
      "Iteration 226, loss = 0.34613367\n",
      "Validation score: 0.859701\n",
      "Iteration 227, loss = 0.34600445\n",
      "Validation score: 0.855721\n",
      "Iteration 228, loss = 0.34769278\n",
      "Validation score: 0.854726\n",
      "Iteration 229, loss = 0.34621152\n",
      "Validation score: 0.855721\n",
      "Iteration 230, loss = 0.34575111\n",
      "Validation score: 0.853731\n",
      "Iteration 231, loss = 0.34676173\n",
      "Validation score: 0.852736\n",
      "Iteration 232, loss = 0.34676750\n",
      "Validation score: 0.856716\n",
      "Iteration 233, loss = 0.34638592\n",
      "Validation score: 0.856716\n",
      "Iteration 234, loss = 0.34640272\n",
      "Validation score: 0.853731\n",
      "Iteration 235, loss = 0.34576935\n",
      "Validation score: 0.856716\n",
      "Iteration 236, loss = 0.34567739\n",
      "Validation score: 0.856716\n",
      "Iteration 237, loss = 0.34551724\n",
      "Validation score: 0.853731\n",
      "Iteration 238, loss = 0.34579044\n",
      "Validation score: 0.858706\n",
      "Iteration 239, loss = 0.34572208\n",
      "Validation score: 0.855721\n",
      "Iteration 240, loss = 0.34586363\n",
      "Validation score: 0.855721\n",
      "Iteration 241, loss = 0.34591175\n",
      "Validation score: 0.855721\n",
      "Iteration 242, loss = 0.34612371\n",
      "Validation score: 0.853731\n",
      "Iteration 243, loss = 0.34613516\n",
      "Validation score: 0.855721\n",
      "Iteration 244, loss = 0.34538707\n",
      "Validation score: 0.855721\n",
      "Iteration 245, loss = 0.34518043\n",
      "Validation score: 0.853731\n",
      "Iteration 246, loss = 0.34611817\n",
      "Validation score: 0.854726\n",
      "Iteration 247, loss = 0.34587811\n",
      "Validation score: 0.852736\n",
      "Iteration 248, loss = 0.34547267\n",
      "Validation score: 0.858706\n",
      "Iteration 249, loss = 0.34523643\n",
      "Validation score: 0.857711\n",
      "Iteration 250, loss = 0.34555351\n",
      "Validation score: 0.857711\n",
      "Iteration 251, loss = 0.34553409\n",
      "Validation score: 0.854726\n",
      "Iteration 252, loss = 0.34534971\n",
      "Validation score: 0.857711\n",
      "Iteration 253, loss = 0.34550908\n",
      "Validation score: 0.856716\n",
      "Iteration 254, loss = 0.34517271\n",
      "Validation score: 0.855721\n",
      "Iteration 255, loss = 0.34526890\n",
      "Validation score: 0.853731\n",
      "Iteration 256, loss = 0.34521411\n",
      "Validation score: 0.856716\n",
      "Iteration 257, loss = 0.34551825\n",
      "Validation score: 0.853731\n",
      "Iteration 258, loss = 0.34698157\n",
      "Validation score: 0.855721\n",
      "Iteration 259, loss = 0.34584456\n",
      "Validation score: 0.853731\n",
      "Iteration 260, loss = 0.34517066\n",
      "Validation score: 0.856716\n",
      "Iteration 261, loss = 0.34501189\n",
      "Validation score: 0.855721\n",
      "Iteration 262, loss = 0.34491675\n",
      "Validation score: 0.855721\n",
      "Iteration 263, loss = 0.34568948\n",
      "Validation score: 0.857711\n",
      "Iteration 264, loss = 0.34571051\n",
      "Validation score: 0.856716\n",
      "Iteration 265, loss = 0.34483673\n",
      "Validation score: 0.853731\n",
      "Iteration 266, loss = 0.34655058\n",
      "Validation score: 0.854726\n",
      "Iteration 267, loss = 0.34508472\n",
      "Validation score: 0.855721\n",
      "Iteration 268, loss = 0.34516958\n",
      "Validation score: 0.856716\n",
      "Iteration 269, loss = 0.34526042\n",
      "Validation score: 0.857711\n",
      "Iteration 270, loss = 0.34473809\n",
      "Validation score: 0.855721\n",
      "Iteration 271, loss = 0.34437832\n",
      "Validation score: 0.856716\n",
      "Iteration 272, loss = 0.34457268\n",
      "Validation score: 0.854726\n",
      "Iteration 273, loss = 0.34533919\n",
      "Validation score: 0.853731\n",
      "Iteration 274, loss = 0.34504353\n",
      "Validation score: 0.854726\n",
      "Iteration 275, loss = 0.34630524\n",
      "Validation score: 0.853731\n",
      "Iteration 276, loss = 0.34478605\n",
      "Validation score: 0.854726\n",
      "Iteration 277, loss = 0.34469878\n",
      "Validation score: 0.852736\n",
      "Iteration 278, loss = 0.34445209\n",
      "Validation score: 0.855721\n",
      "Iteration 279, loss = 0.34463863\n",
      "Validation score: 0.854726\n",
      "Iteration 280, loss = 0.34436337\n",
      "Validation score: 0.853731\n",
      "Iteration 281, loss = 0.34448357\n",
      "Validation score: 0.855721\n",
      "Iteration 282, loss = 0.34480926\n",
      "Validation score: 0.854726\n",
      "Iteration 283, loss = 0.34429550\n",
      "Validation score: 0.856716\n",
      "Iteration 284, loss = 0.34554102\n",
      "Validation score: 0.857711\n",
      "Iteration 285, loss = 0.34402918\n",
      "Validation score: 0.855721\n",
      "Iteration 286, loss = 0.34388694\n",
      "Validation score: 0.855721\n",
      "Iteration 287, loss = 0.34411805\n",
      "Validation score: 0.856716\n",
      "Iteration 288, loss = 0.34395067\n",
      "Validation score: 0.857711\n",
      "Iteration 289, loss = 0.34507734\n",
      "Validation score: 0.854726\n",
      "Iteration 290, loss = 0.34407839\n",
      "Validation score: 0.855721\n",
      "Iteration 291, loss = 0.34443159\n",
      "Validation score: 0.855721\n",
      "Iteration 292, loss = 0.34399232\n",
      "Validation score: 0.855721\n",
      "Iteration 293, loss = 0.34391191\n",
      "Validation score: 0.854726\n",
      "Iteration 294, loss = 0.34389777\n",
      "Validation score: 0.853731\n",
      "Iteration 295, loss = 0.34462403\n",
      "Validation score: 0.855721\n",
      "Iteration 296, loss = 0.34403046\n",
      "Validation score: 0.854726\n",
      "Iteration 297, loss = 0.34395454\n",
      "Validation score: 0.855721\n",
      "Iteration 298, loss = 0.34387492\n",
      "Validation score: 0.856716\n",
      "Iteration 299, loss = 0.34382628\n",
      "Validation score: 0.856716\n",
      "Iteration 300, loss = 0.34358160\n",
      "Validation score: 0.854726\n",
      "Iteration 301, loss = 0.34386718\n",
      "Validation score: 0.854726\n",
      "Iteration 302, loss = 0.34388917\n",
      "Validation score: 0.855721\n",
      "Iteration 303, loss = 0.34323192\n",
      "Validation score: 0.854726\n",
      "Iteration 304, loss = 0.34370060\n",
      "Validation score: 0.855721\n",
      "Iteration 305, loss = 0.34390242\n",
      "Validation score: 0.855721\n",
      "Iteration 306, loss = 0.34367353\n",
      "Validation score: 0.855721\n",
      "Iteration 307, loss = 0.34298542\n",
      "Validation score: 0.852736\n",
      "Iteration 308, loss = 0.34498487\n",
      "Validation score: 0.855721\n",
      "Iteration 309, loss = 0.34320828\n",
      "Validation score: 0.855721\n",
      "Iteration 310, loss = 0.34292241\n",
      "Validation score: 0.854726\n",
      "Iteration 311, loss = 0.34410696\n",
      "Validation score: 0.852736\n",
      "Iteration 312, loss = 0.34341601\n",
      "Validation score: 0.854726\n",
      "Iteration 313, loss = 0.34321542\n",
      "Validation score: 0.853731\n",
      "Iteration 314, loss = 0.34387027\n",
      "Validation score: 0.854726\n",
      "Iteration 315, loss = 0.34307692\n",
      "Validation score: 0.856716\n",
      "Iteration 316, loss = 0.34346559\n",
      "Validation score: 0.854726\n",
      "Iteration 317, loss = 0.34306738\n",
      "Validation score: 0.854726\n",
      "Iteration 318, loss = 0.34351076\n",
      "Validation score: 0.853731\n",
      "Iteration 319, loss = 0.34355972\n",
      "Validation score: 0.852736\n",
      "Iteration 320, loss = 0.34374797\n",
      "Validation score: 0.855721\n",
      "Iteration 321, loss = 0.34320787\n",
      "Validation score: 0.853731\n",
      "Iteration 322, loss = 0.34269681\n",
      "Validation score: 0.856716\n",
      "Iteration 323, loss = 0.34349618\n",
      "Validation score: 0.855721\n",
      "Iteration 324, loss = 0.34494009\n",
      "Validation score: 0.855721\n",
      "Iteration 325, loss = 0.34385232\n",
      "Validation score: 0.856716\n",
      "Iteration 326, loss = 0.34294687\n",
      "Validation score: 0.854726\n",
      "Iteration 327, loss = 0.34295981\n",
      "Validation score: 0.856716\n",
      "Iteration 328, loss = 0.34298221\n",
      "Validation score: 0.853731\n",
      "Iteration 329, loss = 0.34282340\n",
      "Validation score: 0.855721\n",
      "Iteration 330, loss = 0.34291001\n",
      "Validation score: 0.854726\n",
      "Iteration 331, loss = 0.34272265\n",
      "Validation score: 0.854726\n",
      "Iteration 332, loss = 0.34298865\n",
      "Validation score: 0.854726\n",
      "Iteration 333, loss = 0.34276074\n",
      "Validation score: 0.852736\n",
      "Iteration 334, loss = 0.34335084\n",
      "Validation score: 0.854726\n",
      "Iteration 335, loss = 0.34345599\n",
      "Validation score: 0.853731\n",
      "Iteration 336, loss = 0.34276685\n",
      "Validation score: 0.854726\n",
      "Iteration 337, loss = 0.34266581\n",
      "Validation score: 0.854726\n",
      "Iteration 338, loss = 0.34249538\n",
      "Validation score: 0.853731\n",
      "Iteration 339, loss = 0.34266625\n",
      "Validation score: 0.854726\n",
      "Iteration 340, loss = 0.34248765\n",
      "Validation score: 0.855721\n",
      "Iteration 341, loss = 0.34238566\n",
      "Validation score: 0.853731\n",
      "Iteration 342, loss = 0.34248197\n",
      "Validation score: 0.856716\n",
      "Iteration 343, loss = 0.34221301\n",
      "Validation score: 0.855721\n",
      "Iteration 344, loss = 0.34244788\n",
      "Validation score: 0.851741\n",
      "Iteration 345, loss = 0.34262141\n",
      "Validation score: 0.854726\n",
      "Iteration 346, loss = 0.34229612\n",
      "Validation score: 0.852736\n",
      "Iteration 347, loss = 0.34246153\n",
      "Validation score: 0.852736\n",
      "Iteration 348, loss = 0.34192286\n",
      "Validation score: 0.852736\n",
      "Iteration 349, loss = 0.34301245\n",
      "Validation score: 0.851741\n",
      "Iteration 350, loss = 0.34232436\n",
      "Validation score: 0.853731\n",
      "Iteration 351, loss = 0.34267110\n",
      "Validation score: 0.853731\n",
      "Iteration 352, loss = 0.34137568\n",
      "Validation score: 0.854726\n",
      "Iteration 353, loss = 0.34391711\n",
      "Validation score: 0.854726\n",
      "Iteration 354, loss = 0.34220059\n",
      "Validation score: 0.853731\n",
      "Iteration 355, loss = 0.34229481\n",
      "Validation score: 0.852736\n",
      "Iteration 356, loss = 0.34205038\n",
      "Validation score: 0.854726\n",
      "Iteration 357, loss = 0.34220863\n",
      "Validation score: 0.857711\n",
      "Iteration 358, loss = 0.34196840\n",
      "Validation score: 0.855721\n",
      "Iteration 359, loss = 0.34182493\n",
      "Validation score: 0.854726\n",
      "Iteration 360, loss = 0.34180158\n",
      "Validation score: 0.854726\n",
      "Iteration 361, loss = 0.34181518\n",
      "Validation score: 0.856716\n",
      "Iteration 362, loss = 0.34251651\n",
      "Validation score: 0.851741\n",
      "Iteration 363, loss = 0.34192116\n",
      "Validation score: 0.856716\n",
      "Iteration 364, loss = 0.34275950\n",
      "Validation score: 0.855721\n",
      "Iteration 365, loss = 0.34150770\n",
      "Validation score: 0.854726\n",
      "Iteration 366, loss = 0.34151892\n",
      "Validation score: 0.853731\n",
      "Iteration 367, loss = 0.34259896\n",
      "Validation score: 0.852736\n",
      "Iteration 368, loss = 0.34154366\n",
      "Validation score: 0.855721\n",
      "Iteration 369, loss = 0.34162049\n",
      "Validation score: 0.855721\n",
      "Iteration 370, loss = 0.34176213\n",
      "Validation score: 0.854726\n",
      "Iteration 371, loss = 0.34182670\n",
      "Validation score: 0.854726\n",
      "Iteration 372, loss = 0.34240276\n",
      "Validation score: 0.854726\n",
      "Iteration 373, loss = 0.34152230\n",
      "Validation score: 0.857711\n",
      "Iteration 374, loss = 0.34174635\n",
      "Validation score: 0.856716\n",
      "Iteration 375, loss = 0.34122156\n",
      "Validation score: 0.851741\n",
      "Iteration 376, loss = 0.34153888\n",
      "Validation score: 0.855721\n",
      "Iteration 377, loss = 0.34175728\n",
      "Validation score: 0.852736\n",
      "Iteration 378, loss = 0.34178054\n",
      "Validation score: 0.853731\n",
      "Iteration 379, loss = 0.34103311\n",
      "Validation score: 0.853731\n",
      "Iteration 380, loss = 0.34126837\n",
      "Validation score: 0.852736\n",
      "Iteration 381, loss = 0.34171606\n",
      "Validation score: 0.853731\n",
      "Iteration 382, loss = 0.34235609\n",
      "Validation score: 0.853731\n",
      "Iteration 383, loss = 0.34147975\n",
      "Validation score: 0.852736\n",
      "Iteration 384, loss = 0.34227791\n",
      "Validation score: 0.850746\n",
      "Iteration 385, loss = 0.34246690\n",
      "Validation score: 0.858706\n",
      "Iteration 386, loss = 0.34143162\n",
      "Validation score: 0.856716\n",
      "Iteration 387, loss = 0.34114377\n",
      "Validation score: 0.855721\n",
      "Iteration 388, loss = 0.34085335\n",
      "Validation score: 0.854726\n",
      "Iteration 389, loss = 0.34112580\n",
      "Validation score: 0.854726\n",
      "Iteration 390, loss = 0.34039907\n",
      "Validation score: 0.856716\n",
      "Iteration 391, loss = 0.34157838\n",
      "Validation score: 0.854726\n",
      "Iteration 392, loss = 0.34087530\n",
      "Validation score: 0.852736\n",
      "Iteration 393, loss = 0.34071542\n",
      "Validation score: 0.853731\n",
      "Iteration 394, loss = 0.34105689\n",
      "Validation score: 0.854726\n",
      "Iteration 395, loss = 0.34043719\n",
      "Validation score: 0.854726\n",
      "Iteration 396, loss = 0.34072385\n",
      "Validation score: 0.852736\n",
      "Iteration 397, loss = 0.34086079\n",
      "Validation score: 0.855721\n",
      "Iteration 398, loss = 0.34000622\n",
      "Validation score: 0.853731\n",
      "Iteration 399, loss = 0.34084554\n",
      "Validation score: 0.854726\n",
      "Iteration 400, loss = 0.34082914\n",
      "Validation score: 0.854726\n",
      "Iteration 401, loss = 0.34064180\n",
      "Validation score: 0.853731\n",
      "Iteration 402, loss = 0.34238235\n",
      "Validation score: 0.852736\n",
      "Iteration 403, loss = 0.34089555\n",
      "Validation score: 0.853731\n",
      "Iteration 404, loss = 0.34104052\n",
      "Validation score: 0.854726\n",
      "Iteration 405, loss = 0.34088618\n",
      "Validation score: 0.852736\n",
      "Iteration 406, loss = 0.34033307\n",
      "Validation score: 0.852736\n",
      "Iteration 407, loss = 0.34037648\n",
      "Validation score: 0.853731\n",
      "Iteration 408, loss = 0.34053961\n",
      "Validation score: 0.855721\n",
      "Iteration 409, loss = 0.34050748\n",
      "Validation score: 0.852736\n",
      "Iteration 410, loss = 0.34058515\n",
      "Validation score: 0.853731\n",
      "Iteration 411, loss = 0.34042721\n",
      "Validation score: 0.857711\n",
      "Iteration 412, loss = 0.34090769\n",
      "Validation score: 0.855721\n",
      "Iteration 413, loss = 0.34058666\n",
      "Validation score: 0.853731\n",
      "Iteration 414, loss = 0.34056683\n",
      "Validation score: 0.855721\n",
      "Iteration 415, loss = 0.34066596\n",
      "Validation score: 0.853731\n",
      "Iteration 416, loss = 0.34076599\n",
      "Validation score: 0.853731\n",
      "Iteration 417, loss = 0.34091070\n",
      "Validation score: 0.853731\n",
      "Iteration 418, loss = 0.33985011\n",
      "Validation score: 0.852736\n",
      "Iteration 419, loss = 0.34033660\n",
      "Validation score: 0.854726\n",
      "Iteration 420, loss = 0.33967505\n",
      "Validation score: 0.856716\n",
      "Iteration 421, loss = 0.34069006\n",
      "Validation score: 0.853731\n",
      "Iteration 422, loss = 0.34099923\n",
      "Validation score: 0.852736\n",
      "Iteration 423, loss = 0.33994280\n",
      "Validation score: 0.854726\n",
      "Iteration 424, loss = 0.34069072\n",
      "Validation score: 0.854726\n",
      "Iteration 425, loss = 0.33994943\n",
      "Validation score: 0.854726\n",
      "Iteration 426, loss = 0.34012647\n",
      "Validation score: 0.853731\n",
      "Iteration 427, loss = 0.33998237\n",
      "Validation score: 0.852736\n",
      "Validation score did not improve more than tol=0.000100 for 200 consecutive epochs. Stopping.\n",
      "Validation Accuracy: 0.864808362369338\n",
      "Test Accuracy: 0.8544568245125348\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "# Separate the features 'X' and target variable 'y'\n",
    "X = df.drop('Exited', axis=1)  # Assuming 'Exited' is the target variable\n",
    "y = df['Exited']\n",
    "\n",
    "# Split the data into train-validation-test sets (70% training, 15% validation, 15% test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Build the neural network classifier\n",
    "model = MLPClassifier(random_state=42,\n",
    "                      max_iter=1000,\n",
    "                      hidden_layer_sizes=(30, 60),\n",
    "                      activation='logistic',\n",
    "                      validation_fraction=0.15,\n",
    "                      n_iter_no_change=200,\n",
    "                      early_stopping=True,\n",
    "                      verbose=True)\n",
    "\n",
    "# Train the classifier\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86913cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2871, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca95d9f8",
   "metadata": {},
   "source": [
    "Ater running multiple times the model, adjusting the hyper-paramenters, I realized that the best perfomance is using the Logistic Activtion Function. While ReLu generates a similar output, Logistic iterates more in the model (double # of iterations approx) and is also more appropiate for a binary classifier like this example. \n",
    "\n",
    "- As for the hidden layers, I picked two since the data set is small. I also adjusted to different sizes as 50-100, 25-50, 25,50,75 but found that 30 nodes and 60 nodes perfoms better. \n",
    "\n",
    "- Since I'm the logistic activation function for binary classification, the output layer will have a single node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4900456f",
   "metadata": {},
   "source": [
    "# Plotting the Loss Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0579d0",
   "metadata": {},
   "source": [
    "Plot the loss curve of the Neural Network model over the iterations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "243dc97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.loss_curve_)\n",
    "plt.title(\"Loss Curve Over Iterations\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947bee26",
   "metadata": {},
   "source": [
    "- At the beginning, the curve as usual, drops dramatically since it is the beginning of running the model, so it is learning. \n",
    "- Starts from 0.55 and goes to 0.37 by the iteration 100. Then, it becomes more stable and does not change that much until the final result when it stops at 0.37\n",
    "- We see como fluctuations around the iteration 100 but then it kinda stabilize and does not get much lower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904b4915",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0dd3bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8560549499776019"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169306bf",
   "metadata": {},
   "source": [
    "__Confusion Matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1164831b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1110,   32],\n",
       "       [ 177,  117]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions, labels=model.classes_)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18419260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0153ed47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1436, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1124070",
   "metadata": {},
   "source": [
    "From this Confusion Matrix, we can see that:\n",
    "    \n",
    "- True Positives: 117 were correclty classified as positive.\n",
    "- True Negatives: 1110  predicted as Negative and they were negative. \n",
    "- False Positive: 32 of incorrect classifications of negative examples.\n",
    "- False Negative: 117 of incorrect classification of positive examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98567446",
   "metadata": {},
   "source": [
    "__Prediction Score__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86f52339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Train Score of 15% of the data set is: 0.8560549499776019\n",
      "The Validation Score of 15% of the data set is: 0.8596307906652734\n",
      "The Test Score of 15% of the data set is: 0.8544568245125348\n"
     ]
    }
   ],
   "source": [
    "train_score = model.score(X_train, y_train)\n",
    "validation_score = model.score(X_temp, y_temp)\n",
    "test_score = model.score(X_test, y_test)\n",
    "print(f\"The Train Score of 15% of the data set is: {train_score}\")\n",
    "print(f\"The Validation Score of 15% of the data set is: {validation_score}\")\n",
    "print(f\"The Test Score of 15% of the data set is: {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed8f59",
   "metadata": {},
   "source": [
    "__F1 Score__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eae8dd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5282167042889391"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = f1_score(y_test, predictions)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de08a150",
   "metadata": {},
   "source": [
    "# Model Explanation and Perfomance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d3685",
   "metadata": {},
   "source": [
    "In general the model is good given the following metrics:\n",
    "\n",
    "- F1 Score: The F1 score (0.5282) suggests the model is somewhat balanced in making correct positive predictions, but there's room to improvement.\n",
    "\n",
    "- The scores for training, validation, and test sets are similar (aorund 85% all of them), which is good. It's consistent. \n",
    "\n",
    "- Confusion Matrix: The model is making both correct and incorrect predictions. It could improve in identifying positive cases (117 missed) and negative cases (32 mistaken).\n",
    "\n",
    "__Improvements__:\n",
    "\n",
    "- Experiment with different hyperparameter: such as the number of hidden layers, nodes, learning rate, and activation functions.\n",
    "- It is important to focus on avoiding false positives or false negatives, working on the precision and recall.\n",
    "- Take more time to run the model multiple times trying different hyperparamenter combinations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e3d556",
   "metadata": {},
   "source": [
    "Saving the classifier model in a separate pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c17fc958",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Trained_classifier.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b72e72",
   "metadata": {},
   "source": [
    "# New Prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d18481a",
   "metadata": {},
   "source": [
    "Predict the customer churn (should we say goodbye) for the following customer:\n",
    "\n",
    " \n",
    "Geography\t                              France\n",
    "Credit Score\t                          600\n",
    "Gender\t                                  male\n",
    "Tenure\t                                  3 years\n",
    "Number of Products\t                      2\n",
    "Does this customer have a credit card?\t Yes\n",
    "Is this customer an Active Member?\t     Yes\n",
    "Estimated Salary?\t                     50,000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13894477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"Gender\"] = 'Male'\n",
    "#df[\"Geography\"] = 'France'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c73d11",
   "metadata": {},
   "source": [
    "__Loading Objects__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc8ce10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler_model.pkl', 'rb') as scaler_file:\n",
    "    scaler = pickle.load(scaler_file)\n",
    "\n",
    "with open('encoder.pkl', 'rb') as encoder_file:\n",
    "    encoder = pickle.load(encoder_file)\n",
    "\n",
    "# Load the trained classifier\n",
    "with open('trained_classifier.pkl', 'rb') as model_file:\n",
    "    model = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3983ac1",
   "metadata": {},
   "source": [
    "__User Information__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d34d13",
   "metadata": {},
   "source": [
    "Handling missing age and balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c95bfd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3418084353265582e-18\n",
      "-3.37893964016352e-17\n"
     ]
    }
   ],
   "source": [
    "age_mean = df['Age'].mean()\n",
    "print(age_mean)\n",
    "balance_mean = df['Balance'].mean()\n",
    "print(balance_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ea442ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_customer_data =  {\n",
    "    'CreditScore': 600,\n",
    "    'Age': age_mean,\n",
    "    'Tenure': 3,\n",
    "    'Balance': balance_mean,  \n",
    "    'NumOfProducts': 2,\n",
    "    'HasCrCard': 'yes',\n",
    "    'IsActiveMember': '1',\n",
    "    'EstimatedSalary': 50000,\n",
    "    #'Exited': 0,   \n",
    "   # 'Gender_Female': 0,\n",
    "    #'Gender_Male': 1,\n",
    "    #'Geography' : 'France',\n",
    "    #'Gender' : 'Male'\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26639f50",
   "metadata": {},
   "source": [
    "__Data frame__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad061b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>3.341808e-18</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.378940e-17</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore           Age  Tenure       Balance  NumOfProducts HasCrCard  \\\n",
       "0          600  3.341808e-18       3 -3.378940e-17              2       yes   \n",
       "\n",
       "  IsActiveMember  EstimatedSalary  \n",
       "0              1            50000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_customer_df = pd.DataFrame([new_customer_data])\n",
    "new_customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "531094c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Geography</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>3.341808e-18</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.378940e-17</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>50000</td>\n",
       "      <td>male</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore           Age  Tenure       Balance  NumOfProducts HasCrCard  \\\n",
       "0          600  3.341808e-18       3 -3.378940e-17              2       yes   \n",
       "\n",
       "  IsActiveMember  EstimatedSalary Gender Geography  \n",
       "0              1            50000   male    France  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_customer_df['Gender'] = ['male']\n",
    "new_customer_df['Geography'] = ['France']\n",
    "new_customer_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61847bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CreditScore           Age  Tenure       Balance  NumOfProducts HasCrCard  \\\n",
      "0          600  3.341808e-18       3 -3.378940e-17              2       yes   \n",
      "\n",
      "  IsActiveMember  EstimatedSalary  Gender_Female  Gender_Male  \\\n",
      "0              1            50000            0.0          0.0   \n",
      "\n",
      "   Geography_France  Geography_Germany  Geography_Spain  \n",
      "0               1.0                0.0              0.0  \n"
     ]
    }
   ],
   "source": [
    "# Apply one-hot encoding to the 'Gender' and 'Geography' columns\n",
    "categorical_features = [\"Gender\", \"Geography\"]\n",
    "encoded_data = encoder.transform(new_customer_df[categorical_features])\n",
    "encoded_df = pd.DataFrame.sparse.from_spmatrix(encoded_data,\n",
    "                                               columns=encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "# Drop the temporary 'Gender' and 'Geography' columns\n",
    "new_customer_df = new_customer_df.drop(columns=categorical_features)\n",
    "\n",
    "# Concatenate the encoded categorical columns and the rest of the DataFrame\n",
    "new_customer_df = pd.concat([new_customer_df, encoded_df], axis=1)\n",
    "\n",
    "print(new_customer_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab5885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d98d4178",
   "metadata": {},
   "source": [
    "__Apply One-Hot-Encoder__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ee147",
   "metadata": {},
   "source": [
    "__Scaler__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67c6c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = [\"CreditScore\", \"Age\", \"Tenure\", 'Balance', 'NumOfProducts',\n",
    "        'EstimatedSalary']\n",
    "df[columns_to_scale] = scaler.transform(df[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1290c779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.842297</td>\n",
       "      <td>-4.779627</td>\n",
       "      <td>-2.463453</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-10.879824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-6.842309</td>\n",
       "      <td>-4.781103</td>\n",
       "      <td>-2.504980</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-10.879824</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.842429</td>\n",
       "      <td>-4.779627</td>\n",
       "      <td>-2.214288</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>1.158469</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.842207</td>\n",
       "      <td>-4.784055</td>\n",
       "      <td>-2.504980</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-4.860678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.842037</td>\n",
       "      <td>-4.778151</td>\n",
       "      <td>-2.463453</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-10.879824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>-6.842126</td>\n",
       "      <td>-4.784055</td>\n",
       "      <td>-2.338870</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-4.860678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>-6.842413</td>\n",
       "      <td>-4.789960</td>\n",
       "      <td>-2.131233</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-10.879824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>-6.842196</td>\n",
       "      <td>-4.788484</td>\n",
       "      <td>-2.255815</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-10.879824</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9566</th>\n",
       "      <td>-6.842125</td>\n",
       "      <td>-4.779627</td>\n",
       "      <td>-2.421925</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-4.860678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9567</th>\n",
       "      <td>-6.842102</td>\n",
       "      <td>-4.800294</td>\n",
       "      <td>-2.380398</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-10.879824</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9568 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0       -6.842297 -4.779627 -2.463453 -1.224671     -10.879824          1   \n",
       "1       -6.842309 -4.781103 -2.504980 -1.224671     -10.879824          0   \n",
       "2       -6.842429 -4.779627 -2.214288 -1.224671       1.158469          1   \n",
       "3       -6.842207 -4.784055 -2.504980 -1.224671      -4.860678          0   \n",
       "4       -6.842037 -4.778151 -2.463453 -1.224671     -10.879824          1   \n",
       "...           ...       ...       ...       ...            ...        ...   \n",
       "9563    -6.842126 -4.784055 -2.338870 -1.224671      -4.860678          1   \n",
       "9564    -6.842413 -4.789960 -2.131233 -1.224671     -10.879824          1   \n",
       "9565    -6.842196 -4.788484 -2.255815 -1.224671     -10.879824          0   \n",
       "9566    -6.842125 -4.779627 -2.421925 -1.224671      -4.860678          1   \n",
       "9567    -6.842102 -4.800294 -2.380398 -1.224671     -10.879824          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Gender_Female  Gender_Male  \n",
       "0                  1        -1.740195       1            1.0          0.0  \n",
       "1                  1        -1.740195       0            1.0          0.0  \n",
       "2                  0        -1.740195       1            1.0          0.0  \n",
       "3                  0        -1.740195       0            1.0          0.0  \n",
       "4                  1        -1.740195       0            1.0          0.0  \n",
       "...              ...              ...     ...            ...          ...  \n",
       "9563               0        -1.740195       0            0.0          1.0  \n",
       "9564               1        -1.740195       0            0.0          1.0  \n",
       "9565               1        -1.740195       1            1.0          0.0  \n",
       "9566               0        -1.740195       1            0.0          1.0  \n",
       "9567               0        -1.740195       0            1.0          0.0  \n",
       "\n",
       "[9568 rows x 11 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba444b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.842297</td>\n",
       "      <td>-4.779627</td>\n",
       "      <td>-2.463453</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-10.879824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-6.842309</td>\n",
       "      <td>-4.781103</td>\n",
       "      <td>-2.504980</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-10.879824</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.842429</td>\n",
       "      <td>-4.779627</td>\n",
       "      <td>-2.214288</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>1.158469</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.842207</td>\n",
       "      <td>-4.784055</td>\n",
       "      <td>-2.504980</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-4.860678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.842037</td>\n",
       "      <td>-4.778151</td>\n",
       "      <td>-2.463453</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-10.879824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>-6.842126</td>\n",
       "      <td>-4.784055</td>\n",
       "      <td>-2.338870</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-4.860678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>-6.842413</td>\n",
       "      <td>-4.789960</td>\n",
       "      <td>-2.131233</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-10.879824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>-6.842196</td>\n",
       "      <td>-4.788484</td>\n",
       "      <td>-2.255815</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-10.879824</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9566</th>\n",
       "      <td>-6.842125</td>\n",
       "      <td>-4.779627</td>\n",
       "      <td>-2.421925</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-4.860678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9567</th>\n",
       "      <td>-6.842102</td>\n",
       "      <td>-4.800294</td>\n",
       "      <td>-2.380398</td>\n",
       "      <td>-1.224671</td>\n",
       "      <td>-10.879824</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.740195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9568 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0       -6.842297 -4.779627 -2.463453 -1.224671     -10.879824          1   \n",
       "1       -6.842309 -4.781103 -2.504980 -1.224671     -10.879824          0   \n",
       "2       -6.842429 -4.779627 -2.214288 -1.224671       1.158469          1   \n",
       "3       -6.842207 -4.784055 -2.504980 -1.224671      -4.860678          0   \n",
       "4       -6.842037 -4.778151 -2.463453 -1.224671     -10.879824          1   \n",
       "...           ...       ...       ...       ...            ...        ...   \n",
       "9563    -6.842126 -4.784055 -2.338870 -1.224671      -4.860678          1   \n",
       "9564    -6.842413 -4.789960 -2.131233 -1.224671     -10.879824          1   \n",
       "9565    -6.842196 -4.788484 -2.255815 -1.224671     -10.879824          0   \n",
       "9566    -6.842125 -4.779627 -2.421925 -1.224671      -4.860678          1   \n",
       "9567    -6.842102 -4.800294 -2.380398 -1.224671     -10.879824          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Gender_Female  Gender_Male  \n",
       "0                  1        -1.740195            1.0          0.0  \n",
       "1                  1        -1.740195            1.0          0.0  \n",
       "2                  0        -1.740195            1.0          0.0  \n",
       "3                  0        -1.740195            1.0          0.0  \n",
       "4                  1        -1.740195            1.0          0.0  \n",
       "...              ...              ...            ...          ...  \n",
       "9563               0        -1.740195            0.0          1.0  \n",
       "9564               1        -1.740195            0.0          1.0  \n",
       "9565               1        -1.740195            1.0          0.0  \n",
       "9566               0        -1.740195            0.0          1.0  \n",
       "9567               0        -1.740195            1.0          0.0  \n",
       "\n",
       "[9568 rows x 10 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524e6cd3",
   "metadata": {},
   "source": [
    "__Apply Neural Network__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db9c1ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(df)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a094f55",
   "metadata": {},
   "source": [
    "Since I was not given all the features that I used to train my model, I need to come up with an idea to handle these missing values so ill get the mean for age and balance. \n",
    "\n",
    "__The result is 0 which means that the customer is more likely to DO NOT stay!__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70552ed4",
   "metadata": {},
   "source": [
    "__ THE END <3  __ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f538731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
